{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlfavorfit/anaconda3/envs/diffusion_rnd/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Favorfit_image_to_text import clip_image_to_text\n",
    "\n",
    "clip_model = clip_image_to_text.load_interrogator(\"/home/mlfavorfit/Desktop/lib_link/favorfit/kjg/0_model_weights/image_to_text/clip\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "tps = glob(\"/media/mlfavorfit/sdb/favorfit_templates/templates/*/*\")\n",
    "tps += glob(\"/media/mlfavorfit/sdb/favorfit_templates/templates_freepik/*/*\")\n",
    "tps = glob(\"/media/mlfavorfit/sdb/kandinsky_prior_train/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 41/3328 [00:07<07:13,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mlfavorfit/sdb/kandinsky_prior_train/9032.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3328/3328 [10:02<00:00,  5.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# caption_dict = {}\n",
    "for tp in tqdm(tps[8700:], total=len(tps[8700:])):\n",
    "    try:\n",
    "        img = Image.open(tp)\n",
    "        caption = clip_image_to_text.inference(img, clip_model, mode=\"fast\")\n",
    "        caption_dict[os.path.basename(tp)] = f\"{{FavorfitStyle}}, {caption}\"\n",
    "    except:\n",
    "        print(tp)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./caption_dict.json\", mode=\"r\") as f:\n",
    "    json_like = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(json_like.values())\n",
    "texts = [text.split(\", \") for text in texts]\n",
    "main_sent = [text[0] for text in texts]\n",
    "keywords = [text[1:] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_flatten = []\n",
    "for keyword in keywords: keywords_flatten += keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter_keywords = Counter(keywords_flatten)\n",
    "important_keywords = \"natural materials :: high detail, behance. polished, minimalist furniture, soft zen minimalist, trending on textures. com, clean 3 d render, soft geometric 3d shapes, raytraced 3d set design, raytracing shadows, image on the store website, john pawson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "\n",
    "def gen_features(model, text):\n",
    "    tokens = clip.tokenize([text]).to(device)\n",
    "    text_features = model.encode_text(tokens)\n",
    "\n",
    "    return text_features\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    # 정규화\n",
    "    v1_normalized = torch.nn.functional.normalize(v1, p=2, dim=-1)\n",
    "    v2_normalized = torch.nn.functional.normalize(v2, p=2, dim=-1)\n",
    "\n",
    "    # 내적 계산\n",
    "    similarity = torch.matmul(v1_normalized, v2_normalized.transpose(0, 1))\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def dist(caption_embedding, embeddings_tensor):\n",
    "    # 코사인 유사도 계산\n",
    "    similarity = cosine_similarity(caption_embedding, embeddings_tensor)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"ViT-L/14\"\n",
    "model, _ = clip.load(model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings = [gen_features(model, sentence).to(\"cpu\").squeeze() for sentence in main_sent]\n",
    "embeddings_arr = torch.cat(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"./image/kamil.jpg\")\n",
    "caption = clip_image_to_text.inference(img, clip_model, mode=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    caption_embedding = gen_features(model, caption).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_tensor = dist(caption_embedding, embeddings_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1873, 11528, 17520,  8665,  7951, 16123,  7077, 16894, 14176,  4894,\n",
       "         9968, 18673,  1011,  1008, 14538,  5305,  3193, 12676, 19610,  2706,\n",
       "         9019, 17832, 13041,   946,  3606,  9074,  5067, 17882, 14330,  7036,\n",
       "         5029, 14297, 16087, 12004,  2423, 14430,  5176,  8242,  7146,  7046,\n",
       "        16095,  4844, 14132, 15911,  6843,  3975, 13367,  8541, 13441, 17407])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(dist_tensor, descending=True)[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a cup sitting on top of a table'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_sent[17407]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_rnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
