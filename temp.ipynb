{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_movq_dict = dict(torch.load(\"/home/mlfavorfit/.cache/huggingface/hub/models--kandinsky-community--kandinsky-2-2-controlnet-depth/snapshots/4ecd717e8c9086cf4a16ca28b64894f70a42cd08/movq/diffusion_pytorch_model.bin\"))\n",
    "ct_unet_dict = dict(torch.load(\"/home/mlfavorfit/.cache/huggingface/hub/models--kandinsky-community--kandinsky-2-2-controlnet-depth/snapshots/4ecd717e8c9086cf4a16ca28b64894f70a42cd08/unet/diffusion_pytorch_model.bin\"))\n",
    "\n",
    "un_movq_dict = dict(load_file(\"/home/mlfavorfit/.cache/huggingface/hub/models--kandinsky-community--kandinsky-2-2-decoder-inpaint/snapshots/db790ad5cbcabed886f069ef2710774657621702/movq/diffusion_pytorch_model.safetensors\"))\n",
    "un_unet_dict = dict(load_file(\"/home/mlfavorfit/.cache/huggingface/hub/models--kandinsky-community--kandinsky-2-2-decoder-inpaint/snapshots/db790ad5cbcabed886f069ef2710774657621702/unet/diffusion_pytorch_model.safetensors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_movq = sorted([(cur, ct_movq_dict[cur].shape)for cur in ct_movq_dict], key=lambda x:x[0])\n",
    "ct_unet = sorted([(cur, ct_unet_dict[cur].shape)for cur in ct_unet_dict], key=lambda x:x[0])\n",
    "un_movq = sorted([(cur, un_movq_dict[cur].shape)for cur in un_movq_dict], key=lambda x:x[0])\n",
    "un_unet = sorted([(cur, un_unet_dict[cur].shape)for cur in un_unet_dict], key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ct, un in zip(ct_movq, un_movq):\n",
    "    if ct != un: print(\"warn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_ct = []\n",
    "common_ct_un = []\n",
    "for name, shape in ct_unet:\n",
    "    if name in un_unet_dict.keys():\n",
    "        common_ct_un.append(name)\n",
    "    else:\n",
    "        only_ct.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_in.weight\n"
     ]
    }
   ],
   "source": [
    "for name in common_ct_un:\n",
    "    if un_unet_dict[name].shape != ct_unet_dict[name].shape: print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 9, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_unet_dict[\"conv_in.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 8, 3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_unet_dict[\"conv_in.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_embedding.input_hint_block.0.bias torch.Size([16])\n",
      "add_embedding.input_hint_block.0.weight torch.Size([16, 3, 3, 3])\n",
      "add_embedding.input_hint_block.10.bias torch.Size([96])\n",
      "add_embedding.input_hint_block.10.weight torch.Size([96, 96, 3, 3])\n",
      "add_embedding.input_hint_block.12.bias torch.Size([256])\n",
      "add_embedding.input_hint_block.12.weight torch.Size([256, 96, 3, 3])\n",
      "add_embedding.input_hint_block.14.bias torch.Size([4])\n",
      "add_embedding.input_hint_block.14.weight torch.Size([4, 256, 3, 3])\n",
      "add_embedding.input_hint_block.2.bias torch.Size([16])\n",
      "add_embedding.input_hint_block.2.weight torch.Size([16, 16, 3, 3])\n",
      "add_embedding.input_hint_block.4.bias torch.Size([32])\n",
      "add_embedding.input_hint_block.4.weight torch.Size([32, 16, 3, 3])\n",
      "add_embedding.input_hint_block.6.bias torch.Size([32])\n",
      "add_embedding.input_hint_block.6.weight torch.Size([32, 32, 3, 3])\n",
      "add_embedding.input_hint_block.8.bias torch.Size([96])\n",
      "add_embedding.input_hint_block.8.weight torch.Size([96, 32, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for cur in only_ct:\n",
    "    print(cur, ct_unet_dict[cur].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384, 13, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 기존 텐서의 모양과 새로운 모양 정의\n",
    "old_shape = (384, 9, 3, 3)\n",
    "new_shape = (384, 13, 3, 3)\n",
    "\n",
    "# 새로운 텐서 생성 및 기존 텐서 값 복사\n",
    "new_weight = torch.zeros(new_shape)  # 새로운 텐서를 모두 0으로 초기화\n",
    "old_weight = un_unet_dict[\"conv_in.weight\"]\n",
    "new_weight[:, :old_shape[1], :, :] = old_weight\n",
    "\n",
    "# 추가된 부분에 랜덤한 0으로 채우기\n",
    "random_part = torch.zeros((new_shape[0], new_shape[1] - old_shape[1], new_shape[2], new_shape[3]))\n",
    "new_weight[:, old_shape[1]:, :, :] = random_part\n",
    "\n",
    "# 결과 확인\n",
    "print(new_weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_unet_dict[\"conv_in.weight\"] = new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur in only_ct:\n",
    "    un_unet_dict[cur] = ct_unet_dict[cur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\n",
      "torch.Size([384, 13, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(len(un_unet_dict))\n",
    "print(un_unet_dict[\"conv_in.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import save_file\n",
    "\n",
    "save_file(un_unet_dict, \"/home/mlfavorfit/Desktop/lib_link/favorfit/kjg/0_model_weights/diffusion/Kandinsky/kandinsky-inpainting-controlnet/unet/diffusion_pytorch_model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = load_file(\"/home/mlfavorfit/Desktop/lib_link/favorfit/kjg/0_model_weights/diffusion/Kandinsky/kandinsky-inpainting-controlnet/unet/diffusion_pytorch_model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\n",
      "torch.Size([384, 13, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(len(temp_dict))\n",
    "print(temp_dict[\"conv_in.weight\"].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_rnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
